{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mike Babb\n",
    "# babbm@uw.edu\n",
    "# Find Anagrams\n",
    "## Part 1: Structure the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard libraries - installed by default\n",
    "import collections\n",
    "import itertools\n",
    "import os\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# external libraries - not installed by default\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom, user-defined functions\n",
    "from part_00_process_functions import save_pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set input and output paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path and name of input data\n",
    "in_file_path = '/git/finding_anagrams/data/'\n",
    "in_file_name = 'words.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the input file path\n",
    "in_fpn = os.path.join(in_file_path, in_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to output directories\n",
    "base_output_file_path = '/project/finding_anagrams'\n",
    "data_output_file_path = os.path.join(base_output_file_path, 'data')\n",
    "tabulation_output_file_path = os.path.join(base_output_file_path, 'tabulations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the data output path\n",
    "if os.path.exists(data_output_file_path):\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(data_output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the tabulation output path\n",
    "if os.path.exists(tabulation_output_file_path):\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(tabulation_output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import list of words, shape data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pandas to load the data\n",
    "# htps://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n",
    "print('...Reading in list of words...')\n",
    "word_df = pd.read_csv(filepath_or_buffer = in_fpn, sep = ',', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the first few rows\n",
    "word_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify a a more appropriate column name\n",
    "col_names = ['word']\n",
    "word_df.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many words are we working with?\n",
    "n_words = len(word_df)\n",
    "print('...found', '{:,}'.format(n_words), 'words to find anagrams for...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the only column to a string - just to be safe.\n",
    "# 'nan' is a word in the dictionary. 'nan' is an internal python value.\n",
    "# same with 'null'\n",
    "word_df['word'] = word_df['word'].astype(np.str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lower case values of the words\n",
    "word_df['lcase'] = word_df['word'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove hyphens\n",
    "word_df['lcase'] = word_df['lcase'].str.replace('-', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now drop duplicates, based on the lowercase version of each word\n",
    "word_df = word_df.drop_duplicates('lcase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find word length\n",
    "word_df['n_chars'] = word_df['lcase'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the first letter of each word\n",
    "word_df['first_letter'] = word_df['lcase'].str[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an index\n",
    "word_df['word_id'] = range(0, len(word_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a hash id to capture the sorted letters in each word\n",
    "# use map() with a lambda function to chain several operations together\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.map.html\n",
    "word_df['hash_id'] = word_df['lcase'].map(lambda x: hash(''.join(sorted(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of the hash values using zip\n",
    "# https://docs.python.org/3/library/functions.html#zip\n",
    "hash_id_dict = {hash_id:word_group_id for word_group_id, hash_id in zip(word_df['word_id'], word_df['hash_id'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df['word_group_id'] = word_df['hash_id'].map(hash_id_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the hash id, no longer needed\n",
    "word_df = word_df.drop('hash_id', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use dictionary comprehension to store the letter and the\n",
    "# index of the letter for fast look ups\n",
    "letter_dict = {l:li for li, l in enumerate(string.ascii_lowercase)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sorted list of letters from the dictionary keys\n",
    "letters = sorted(letter_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the unique letters in each word and then sort those letters\n",
    "word_df['letter_group'] = word_df['lcase'].map(lambda x: ''.join(sorted(set(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### count letter frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# several versions of the anagram determination require subsetting by letters in each word. \n",
    "# generate those data and use a ranking technique to help with anagram group identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a counter object to count the occurence of each letter\n",
    "# counters are a special type of dictionary. \n",
    "# https://docs.python.org/3/library/collections.html#collections.Counter\n",
    "# very fast\n",
    "letter_counter = collections.Counter()\n",
    "# enumerate each word and then each letter\n",
    "for i_cw, curr_word in enumerate(word_df['lcase']):    \n",
    "    for i_cl, cl in enumerate(curr_word):\n",
    "        letter_counter[cl] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataframe from the counter object and then order from low to high\n",
    "letter_count_df = pd.DataFrame.from_dict(data=letter_counter, orient = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_count_df = letter_count_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_count_df.columns = ['letter', 'letter_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_count_df = letter_count_df.sort_values(by = 'letter_count', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_count_df['rank'] = range(1, len(letter_count_df) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_count_df['letter_percent'] = letter_count_df['letter_count'] / letter_count_df['letter_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_count_df.head(n=30)\n",
    "# j is the least common letter while e is the most common letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join with the count of words that start with a focal letter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_df = word_df['first_letter'].groupby(word_df['first_letter']).agg(np.size).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_df.columns = ['n_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_df = word_count_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_df['word_percent'] = word_count_df['n_words'] / word_count_df['n_words'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_df = word_count_df.sort_values(by='n_words', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_df['word_count_rank'] = range(1, len(word_count_df) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joins\n",
    "letter_count_df = pd.merge(left=letter_count_df, right = word_count_df,\n",
    "                          left_on=['letter'], right_on = ['first_letter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_count_df = letter_count_df.drop('first_letter', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort and reorder the columns\n",
    "letter_count_df = letter_count_df.sort_values(by = 'letter')\n",
    "col_names = ['letter','letter_count','letter_percent','rank','n_words','word_percent','word_count_rank']\n",
    "letter_count_df = letter_count_df[col_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# place the letter and its rank into a dictionary \n",
    "# as well as the rank and the corresponding letter\n",
    "# {'k':21, 21:'k'}\n",
    "letter_count_rank_dict = {}\n",
    "for cl, clr in zip(letter_count_df['letter'], letter_count_df['rank']):\n",
    "    letter_count_rank_dict[cl] = clr\n",
    "    letter_count_rank_dict[clr] = cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what letter is ranked 21st?\n",
    "letter_count_rank_dict[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the rank of letter k?\n",
    "letter_count_rank_dict['k']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function to order the unique letters in each word by\n",
    "# least common letter to most common letter\n",
    "def get_least_common_letters(x):    \n",
    "    if len(x) == 1:\n",
    "        lcl = x\n",
    "    else:\n",
    "        # ranking of each letter\n",
    "        rank_list = [letter_count_rank_dict[curr_letter] for curr_letter in x]        \n",
    "        # sort the ranking\n",
    "        rank_list = sorted(rank_list, reverse = True)\n",
    "        # generate the letters sorted by rank\n",
    "        rank_list = [letter_count_rank_dict[curr_letter] for curr_letter in rank_list]\n",
    "        lcl = ''.join(rank_list)\n",
    "    return lcl\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract letters by ranking\n",
    "word_df['letter_group_ranked'] = word_df['letter_group'].map(get_least_common_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate the character matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the occurences of each letter in each word and store the results in a matrix\n",
    "# populate the char_matrix and the word_id dictionary\n",
    "# Use the apply function to the word_df. Effectively, apply a function to each row in the \n",
    "# dataframe\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html\n",
    "\n",
    "# Upon intialization, the char_matrix is all zero.\n",
    "# the entry for emit (as do the entriees for time, mite, item) has the following value:\n",
    "# ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "# [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
    "# we need to find all words that have matching rows with at least these values.\n",
    "# for example, 'terminator'.\n",
    "# ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "# [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "# the zero-filled matrix will be populated once the \n",
    "# score_row() function is applied to the word_df\n",
    "char_matrix = np.zeros(shape=(len(word_df), 26), dtype=np.int32)\n",
    "# same with the word_dict.\n",
    "word_dict = {}\n",
    "def score_word(row):\n",
    "    # get a word from the current row\n",
    "    curr_word = row['lcase']    \n",
    "    ri = row['word_id'] # row index / word index\n",
    "    word_length = row['n_chars'] # number of character in each word\n",
    "    first_letter = row['first_letter'] # first letter of the word\n",
    "    letter_group = row['letter_group'] # letter group\n",
    "    letter_group_ranked = row['letter_group_ranked'] # letter group ranked\n",
    "    word_dict[ri] = (curr_word, word_length, first_letter, letter_group, letter_group_ranked)\n",
    "    # populate the char matrix\n",
    "    for i_letter, letter in enumerate(curr_word):\n",
    "        if letter in letter_dict:\n",
    "            # find the corresponding column index of that letter\n",
    "            li = letter_dict[letter]\n",
    "            # increment the count of letters in the current row and current column\n",
    "            char_matrix[ri, li] += 1\n",
    "    return None\n",
    "\n",
    "# catch the output from the function and delete\n",
    "output = word_df.apply(score_word, 1)\n",
    "del output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many letters are in use in our words?\n",
    "char_matrix.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what about if we wanted to see how many times the letter 'e' is used?\n",
    "char_matrix[:, 4].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the same as:\n",
    "letter_counter['e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the percentage of characters that feature the letter 'e'?\n",
    "char_matrix[:, 4].sum() / char_matrix.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see how many words have the letter 'a' in them or the letter 's'. \n",
    "for curr_letter, letter_index in letter_dict.items():    \n",
    "    outcome = np.where(char_matrix[:, letter_index] > 0)\n",
    "    n_rows = np.shape(outcome)[1]        \n",
    "    print(curr_letter, n_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save data to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the char matrix\n",
    "output_name = 'char_matrix.npy'\n",
    "opn = os.path.join(data_output_file_path, output_name)\n",
    "np.save(file = opn, arr = char_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# letter dictionary\n",
    "output_name = 'letter_dict.pkl'\n",
    "save_pickle(file_path = data_output_file_path, file_name = output_name, obj = letter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word dictionary\n",
    "output_name = 'word_dict.pkl'\n",
    "save_pickle(file_path = data_output_file_path, file_name = output_name, obj = word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the word df\n",
    "output_name = 'word_df.csv'\n",
    "opn = os.path.join(data_output_file_path, output_name)\n",
    "word_df.to_csv(path_or_buf = opn, sep = '\\t', header = True, index = False)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### count sub-matrices for processing option 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# option 2: by letter count\n",
    "df02 = word_df['n_chars'].groupby(word_df['n_chars']).agg(np.size).to_frame()\n",
    "df02.columns = ['n_words']\n",
    "df02 = df02.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df02 = df02.sort_values(by='n_chars', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this determines the number of rows in each submatrix\n",
    "df02['total_words'] = df02['n_words'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df02 = df02.sort_values(by='n_chars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df02.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### count sub-matrices for processing option 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the word_ids as an numpy arry\n",
    "word_id_list = word_df['word_id'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# option 3: by letter count and presence of first letter\n",
    "first_letter_df = word_df[['n_chars', 'first_letter']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many sub-matrices?\n",
    "n_sub_matrices = len(first_letter_df)\n",
    "print('...creating', n_sub_matrices, 'sub matrices')\n",
    "output_list = []\n",
    "\n",
    "# create dictionaries to expedite this. We only need to determine the sets of rows of each component\n",
    "# once. After determination, we can store in a dictionary and then look up.\n",
    "# this will hold the set of rows by word length\n",
    "n_char_word_id_list_dict = {}\n",
    "# this will hold the set of rows by presence of the first letter\n",
    "fl_word_id_list_dict = {}\n",
    "\n",
    "loop_count = 0\n",
    "for n_chars, fl in zip(first_letter_df['n_chars'], first_letter_df['first_letter']):\n",
    "        \n",
    "    # word id by character length - check if the set of row ids have already been identified\n",
    "    # if not, create it and store it\n",
    "    if n_chars in n_char_word_id_list_dict:\n",
    "        curr_n_char_word_id_set = n_char_word_id_list_dict[n_chars]\n",
    "    else:\n",
    "        # extract the row ids that meet the criteria,\n",
    "        # use the word_df for this.\n",
    "        curr_n_char_word_id_set  = word_df.loc[(word_df['n_chars']>=n_chars), 'word_id'].tolist()\n",
    "        # create a set\n",
    "        curr_n_char_word_id_set = set(curr_n_char_word_id_set)\n",
    "        # store\n",
    "        n_char_word_id_list_dict[n_chars] = curr_n_char_word_id_set\n",
    "    \n",
    "    # word id by letter match\n",
    "    # use the char_matrix to identify these rows\n",
    "    if fl in fl_word_id_list_dict:\n",
    "        curr_letter_select_word_id_set = fl_word_id_list_dict[fl]\n",
    "    else:                       \n",
    "        # build the oolumn selector using list comprehension\n",
    "        column_selector = [letter_dict[curr_letter] for curr_letter in fl]\n",
    "        \n",
    "        # create a true-false matrix where only certain columns, corresponding to\n",
    "        # letter indices, have a value of 1 or more\n",
    "        outcome = char_matrix[:, column_selector] > 0    \n",
    "        \n",
    "        # which rows in the above matrix evaluate to all True\n",
    "        outcome_indices = np.all(a = outcome, axis = 1)\n",
    "        \n",
    "        # these indices match with the word_id_list, perform the subset        \n",
    "        curr_letter_select_word_id_set = word_id_list[outcome_indices]\n",
    "        curr_letter_select_word_id_set = set(curr_letter_select_word_id_set)\n",
    "        fl_word_id_list_dict[fl] = curr_letter_select_word_id_set        \n",
    "        \n",
    "    # perform the intersection\n",
    "    curr_word_id_set = curr_n_char_word_id_set.intersection(curr_letter_select_word_id_set)\n",
    "    curr_nrows = len(curr_word_id_set)\n",
    "    curr_list = [fl, n_chars, curr_nrows]\n",
    "    output_list.append(curr_list)\n",
    "    \n",
    "    loop_count += 1\n",
    "    if loop_count % 100 == 0:\n",
    "        print(loop_count)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df03 = pd.DataFrame(data=output_list, columns = ['focal_letter', 'n_chars', 'n_words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make it wide\n",
    "df03_wide =  pd.pivot_table(data = df03,\n",
    "                            values = 'n_words',\n",
    "                            index = 'focal_letter',\n",
    "                            columns = 'n_chars',\n",
    "                            fill_value = 0\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df03_wide = df03_wide.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df03_wide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df03['n_words'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### count sub-matrices for processing option 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# option 4: by letter count and presence of least two common letters\n",
    "n_common_letters = 2\n",
    "word_df['letter_selector'] = word_df['letter_group_ranked'].str[:n_common_letters]\n",
    "letter_selector_df = word_df[['n_chars', 'letter_selector']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sub_matrices = len(letter_selector_df)\n",
    "print('...creating', n_sub_matrices, 'sub matrices')\n",
    "\n",
    "output_list = []\n",
    "# same as above - store the set of row ids that match the words of at least a given length\n",
    "n_char_word_id_list_dict = {}\n",
    "# the set of rows ids that contain the words with the n_common_letters\n",
    "ls_word_id_list_dict = {}\n",
    "\n",
    "loop_count = 0\n",
    "for n_chars, ls in zip(letter_selector_df['n_chars'], letter_selector_df['letter_selector']):\n",
    "        \n",
    "    # word id by character length\n",
    "    if n_chars in n_char_word_id_list_dict:\n",
    "        curr_n_char_word_id_set = n_char_word_id_list_dict[n_chars]\n",
    "    else:\n",
    "        curr_n_char_word_id_set  = word_df.loc[(word_df['n_chars']>=n_chars) , 'word_id'].tolist()\n",
    "        curr_n_char_word_id_set = set(curr_n_char_word_id_set)\n",
    "        n_char_word_id_list_dict[n_chars] = curr_n_char_word_id_set\n",
    "    \n",
    "    # word id by presense of least common letters\n",
    "    if ls in ls_word_id_list_dict:\n",
    "        curr_letter_select_word_id_set = ls_word_id_list_dict[ls]\n",
    "    else:                       \n",
    "        # build the oolumn selector using list comprehension\n",
    "        column_selector = [letter_dict[curr_letter] for curr_letter in ls]\n",
    "        \n",
    "        # create a true-false matrix where only certain columns, corresponding to\n",
    "        # letter indices, have a value of 1 or more\n",
    "        outcome = char_matrix[:, column_selector] > 0    \n",
    "        \n",
    "        # which rows in the above matrix evaluate to all True\n",
    "        outcome_indices = np.all(a = outcome, axis = 1)\n",
    "        \n",
    "        # these indices match with the word_is_list, perform the subset        \n",
    "        curr_letter_select_word_id_set = word_id_list[outcome_indices]\n",
    "        curr_letter_select_word_id_set = set(curr_letter_select_word_id_set)\n",
    "        ls_word_id_list_dict[ls] = curr_letter_select_word_id_set        \n",
    "        \n",
    "    # perform the intersection\n",
    "    curr_word_id_set = curr_n_char_word_id_set.intersection(curr_letter_select_word_id_set)\n",
    "    curr_nrows = len(curr_word_id_set)\n",
    "    # store the counts in the list\n",
    "    curr_list = [ls, n_chars, curr_nrows]\n",
    "    output_list.append(curr_list)\n",
    "    \n",
    "    loop_count += 1\n",
    "    if loop_count % 100 == 0:\n",
    "        print(loop_count)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df04 = pd.DataFrame(data=output_list, columns = ['letter_group', 'n_chars', 'n_words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make it wide\n",
    "df04_wide =  pd.pivot_table(data = df04,\n",
    "                            values = 'n_words',\n",
    "                            index = 'letter_group',\n",
    "                            columns = 'n_chars',\n",
    "                            fill_value = 0\n",
    "                           )\n",
    "df04_wide = df04_wide.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df04_wide.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the counts of sub-matrices to an excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframes statistics to an excel file\n",
    "e_writer_file_name = 'matrix_extraction_option_counts.xlsx'\n",
    "e_writer_file_path_name = os.path.join(tabulation_output_file_path, e_writer_file_name)\n",
    "e_writer = pd.ExcelWriter(path=e_writer_file_path_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df02.to_excel(excel_writer = e_writer, sheet_name = 'me_02', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df03.to_excel(excel_writer = e_writer, sheet_name = 'me_03', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df03_wide.to_excel(excel_writer = e_writer, sheet_name = 'me_03_wide', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df04.to_excel(excel_writer = e_writer, sheet_name = 'me_04', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df04_wide.to_excel(excel_writer = e_writer, sheet_name = 'me_04_wide', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort and reorder the the letter count df columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_count_df = letter_count_df.sort_values(by = 'letter')\n",
    "\n",
    "col_names = ['letter','letter_count','letter_percent','rank','n_words','word_percent','word_count_rank']\n",
    "\n",
    "letter_count_df = letter_count_df[col_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_count_df.to_excel(excel_writer = e_writer, sheet_name = 'letter_rank', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and close the excel file object\n",
    "e_writer.save()\n",
    "e_writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
